[
  {
    "objectID": "Our Model/Regression-Analysis.html",
    "href": "Our Model/Regression-Analysis.html",
    "title": "Predicting Asthma Prevalence by Census Tracts in Philadeplhia, PA",
    "section": "",
    "text": "# Regression Analysis & Cross-Validation\n\n\n\n\n\n\n\n\n\n\n\n\n\nC:\\Users\\cruse\\mambaforge1\\envs\\musa-550-fall-2023\\lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:39: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def nb_dist(x, y):\nC:\\Users\\cruse\\mambaforge1\\envs\\musa-550-fall-2023\\lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:165: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def get_faces(triangle):\nC:\\Users\\cruse\\mambaforge1\\envs\\musa-550-fall-2023\\lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:199: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def build_faces(faces, triangles_is, num_triangles, num_faces_single):\nC:\\Users\\cruse\\mambaforge1\\envs\\musa-550-fall-2023\\lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:261: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def nb_mask_faces(mask, faces):\n\n\n\n## Plotting A Correlation Matrix\n\n\n\nCode\nregression_df = pd.read_csv('regression_df.csv')\n\n\n\n\nCode\nmodel = LinearRegression()\nmodel\n\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\n\nCode\nX = regression_df[['hw_value', 'oc_value', 'pmc_value', 'E_PARK', 'E_HOUAGE', 'smoking_prevalance','E_ROAD','blk_percent','white_percent','latino_percent', 'asian_percent', 'other_percent']].values\ny = regression_df['asthma_prevalance'].values\n\n\n\n\nCode\nfeature_cols = [col for col in regression_df.columns if col not in [\"asthma_prevalance\", \"geoid\"]]\ntrain_set, test_set = train_test_split(regression_df, test_size=0.3, random_state=42)\ny_train = train_set[\"asthma_prevalance\"].values\ny_test = test_set[\"asthma_prevalance\"].values\nX_train = train_set[feature_cols].values\nX_test = test_set[feature_cols].values\n\n\n\n\nCode\nsns.heatmap(\n    train_set[feature_cols].corr(), \n    cmap=\"coolwarm\", \n    annot=True, \n    vmin=-1, \n    vmax=1\n);\n\n\n\n\n\n\n\nCode\nX.shape\n\n\n(1179, 12)\n\n\n\n\nCode\ny.shape\n\n\n(1179,)\n\n\n\n\nCode\nmodel.fit(X, y)\n\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\n\nCode\nRsq = model.score(X, y)\nRsq\n\n\n0.8813734475169395\n\n\n\n\nCode\nlinear_pipe = make_pipeline(StandardScaler(), LinearRegression())\n\nprint(\"Linear regression\")\nlinear_pipe.fit(X_train, y_train)\n\ntraining_score = linear_pipe.score(X_train, y_train)\nprint(f\"Training Score = {training_score}\")\n\ntest_score = linear_pipe.score(X_test, y_test)\nprint(f\"Test Score = {test_score}\")\n\n\nLinear regression\nTraining Score = 0.8771018545312711\nTest Score = 0.889628138385183\n\n\n\n\nCode\nforest_pipe = make_pipeline(\n    StandardScaler(),  # Pre-process step\n    RandomForestRegressor(n_estimators=100, max_depth=2, random_state=42),  # Model step\n)\n\nprint(\"Random forest\")\nforest_pipe.fit(X_train, y_train)\n\ntraining_score = forest_pipe.score(X_train, y_train)\nprint(f\"Training Score = {training_score}\")\n\ntest_score = forest_pipe.score(X_test, y_test)\nprint(f\"Test Score = {test_score}\")\n\n\nRandom forest\nTraining Score = 0.802226720882675\nTest Score = 0.7982253593098484\n\n\n\n\nCode\nforest_pipe.named_steps\nforest_model = forest_pipe['randomforestregressor']\n\n\n\n\nCode\nforest_model.feature_importances_\n\n\narray([0.13976872, 0.        , 0.        , 0.3803543 , 0.        ,\n       0.        , 0.        , 0.04474563, 0.43513135, 0.        ,\n       0.        , 0.        ])\n\n\n\n\nCode\nimportance = pd.DataFrame(\n    {\"Feature\": feature_cols, \"Importance\": forest_model.feature_importances_}\n).sort_values(\"Importance\", ascending=False)\n\n\n\n\nCode\nimportance\n\n\n\n\n\n\n\n\n\nFeature\nImportance\n\n\n\n\n8\nwhite_percent\n0.435131\n\n\n3\nsmoking_prevalance\n0.380354\n\n\n0\nhw_value\n0.139769\n\n\n7\nblk_percent\n0.044746\n\n\n1\noc_value\n0.000000\n\n\n2\npmc_value\n0.000000\n\n\n4\nE_PARK\n0.000000\n\n\n5\nE_HOUAGE\n0.000000\n\n\n6\nE_ROAD\n0.000000\n\n\n9\nlatino_percent\n0.000000\n\n\n10\nasian_percent\n0.000000\n\n\n11\nother_percent\n0.000000\n\n\n\n\n\n\n\n\n\nCode\nimport hvplot.pandas\nimportance.sort_values(\"Importance\", ascending=True).hvplot.barh(\n    x=\"Feature\", y=\"Importance\", title=\"Factors that Impact Asthma Prevalance\"\n)\n\n\n\n\n\n\n  \n\n\n\n\n\n\nCode\nmodel = linear_pipe['linearregression']\n\n\n\n\nCode\nlinear_pipe = make_pipeline(StandardScaler(), LinearRegression())\n\n# Run the 3-fold cross validation\nscores = cross_val_score(\n    linear_pipe,\n    X_train,\n    y_train,\n    cv=3,\n)\n\n# Report\nprint(\"R^2 scores = \", scores)\nprint(\"Scores mean = \", scores.mean())\nprint(\"Score std dev = \", scores.std())\n\n\nR^2 scores =  [0.87672721 0.86979481 0.86632107]\nScores mean =  0.8709476945361351\nScore std dev =  0.004325797875727253\n\n\n\n\nCode\nforest_pipe = make_pipeline(\n    StandardScaler(), RandomForestRegressor(n_estimators=100, random_state=42)\n)\n\n# Run the 3-fold cross validation\nscores = cross_val_score(\n    forest_pipe,\n    X_train,\n    y_train,\n    cv=3,\n)\n\n# Report\nprint(\"R^2 scores = \", scores)\nprint(\"Scores mean = \", scores.mean())\nprint(\"Score std dev = \", scores.std())\n\n\nR^2 scores =  [0.8692119  0.91654952 0.9188434 ]\nScores mean =  0.9015349385674881\nScore std dev =  0.022875019221878082\n\n\n\n\nCode\npipe = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=42))\npipe\n\n\nPipeline(steps=[('standardscaler', StandardScaler()),\n                ('randomforestregressor',\n                 RandomForestRegressor(random_state=42))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('standardscaler', StandardScaler()),\n                ('randomforestregressor',\n                 RandomForestRegressor(random_state=42))])StandardScalerStandardScaler()RandomForestRegressorRandomForestRegressor(random_state=42)\n\n\n\n\nCode\npipe.named_steps\n\n\n{'standardscaler': StandardScaler(),\n 'randomforestregressor': RandomForestRegressor(random_state=42)}\n\n\n\n\nCode\nmodel_step = \"randomforestregressor\"\nparam_grid = {\n    f\"{model_step}__n_estimators\": [5, 10, 15, 20, 30, 50, 100, 200],\n    f\"{model_step}__max_depth\": [2, 5, 7, 9, 13, 21, 33, 51],\n}\n\nparam_grid\n\n\n{'randomforestregressor__n_estimators': [5, 10, 15, 20, 30, 50, 100, 200],\n 'randomforestregressor__max_depth': [2, 5, 7, 9, 13, 21, 33, 51]}\n\n\n\n\nCode\ngrid = GridSearchCV(pipe, param_grid, cv=3, verbose=1)\ngrid.fit(X_train, y_train)\n\n\nFitting 3 folds for each of 64 candidates, totalling 192 fits\n\n\nGridSearchCV(cv=3,\n             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n                                       ('randomforestregressor',\n                                        RandomForestRegressor(random_state=42))]),\n             param_grid={'randomforestregressor__max_depth': [2, 5, 7, 9, 13,\n                                                              21, 33, 51],\n                         'randomforestregressor__n_estimators': [5, 10, 15, 20,\n                                                                 30, 50, 100,\n                                                                 200]},\n             verbose=1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=3,\n             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n                                       ('randomforestregressor',\n                                        RandomForestRegressor(random_state=42))]),\n             param_grid={'randomforestregressor__max_depth': [2, 5, 7, 9, 13,\n                                                              21, 33, 51],\n                         'randomforestregressor__n_estimators': [5, 10, 15, 20,\n                                                                 30, 50, 100,\n                                                                 200]},\n             verbose=1)estimator: PipelinePipeline(steps=[('standardscaler', StandardScaler()),\n                ('randomforestregressor',\n                 RandomForestRegressor(random_state=42))])StandardScalerStandardScaler()RandomForestRegressorRandomForestRegressor(random_state=42)\n\n\n\n\nCode\ndef evaluate_mape(model, X_test, y_test):\n    \"\"\"\n    Given a model and test features/targets, print out the \n    mean absolute error and accuracy\n    \"\"\"\n    # Make the predictions\n    predictions = model.predict(X_test)\n\n    # Absolute error\n    errors = abs(predictions - y_test)\n    avg_error = np.mean(errors)\n\n    # Mean absolute percentage error\n    mape = 100 * np.mean(errors / y_test)\n\n    # Accuracy\n    accuracy = 100 - mape\n\n    print(\"Model Performance\")\n    print(f\"Average Absolute Error: {avg_error:0.4f}\")\n    print(f\"Accuracy = {accuracy:0.2f}%.\")\n\n    return accuracy\n\n\n\n\nCode\nbase_model = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=42))\n\n# Fit the training set\nbase_model.fit(X_train, y_train)\n\n# Evaluate on the test set\nbase_accuracy = evaluate_mape(base_model, X_test, y_test)\n\n\nModel Performance\nAverage Absolute Error: 0.2733\nAccuracy = 97.68%.\n\n\n\n\nCode\ndata = regression_df.loc[test_set.index]\n\n\n\ncensustracts = gpd.read_file('Census_Tracts_2010.geojson')\ntract_and_geoid = censustracts[['GEOID10', 'TRACTCE10']]\ntract_and_geoid = tract_and_geoid.rename(columns = {'TRACTCE10':'tract'})\n\ncensustracts = censustracts[['GEOID10', 'geometry']]\ncensustracts = censustracts.rename(columns = {'GEOID10':'geoid'})\ncensustracts['geoid'] = censustracts['geoid'].astype(np.int64)\n\n\n\nCode\ndata['prediction'] = base_model.predict(X_test)\ndata.to_csv('data.csv', index=False)\n\n\n\n\nCode\ndata = pd.merge(data, censustracts, on='geoid', how ='inner')\n\n\n\n\nCode\ndata = gpd.GeoDataFrame(data, geometry = 'geometry')\n\n\n\n\nCode\nfig, axs = plt.subplots(ncols=2, figsize=(10, 10))\n\n# Predicted values\ndata.plot(\n    ax=axs[0],\n    column='prediction',\n    legend=True,\n    cmap='viridis',\n    linewidth=0.8,\n    edgecolor='0.8',\n    legend_kwds={'label': \"Predicted Asthma Prevalence\", 'orientation': \"horizontal\", 'shrink': 0.8}\n)\naxs[0].set_title(\"Predicted Asthma Prevalence\")\n\n# Actual values\ndata.plot(\n    ax=axs[1],\n    column='asthma_prevalance',\n    legend=True,\n    cmap='viridis',\n    linewidth=0.8,\n    edgecolor='0.8',\n    legend_kwds={'label': \"Actual Asthma Prevalence\", 'orientation': \"horizontal\", 'shrink': 0.8}\n)\naxs[1].set_title(\"Actual Asthma Prevalence\")\n\naxs[0].set_axis_off()\naxs[1].set_axis_off()\n\nplt.show()\n\n\n\n\n\n\n\nCode\n\n\n\nTypeError: Cannot interpret '&lt;geopandas.array.GeometryDtype object at 0x00000286BF603E80&gt;' as a data type"
  },
  {
    "objectID": "Our Model/index.html",
    "href": "Our Model/index.html",
    "title": "Analysis",
    "section": "",
    "text": "Analysis\nThis section includes examples of technical analysis done using Jupyter notebooks. Each sub-section highlights different types of analyses and visualizations. In particular, it highlights that we can easily publish interactive visualizations produced with packages such as hvPlot, altair, or Folium, without losing any of the interactive features.\nOn this page, you might want to share more introductory or background information about the analyses to help guide the reader."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MUSA 550 Final Project Template",
    "section": "",
    "text": "We can create beautiful websites that describe complex technical analyses in Python using Quarto and deploy them online using GitHub Pages. This combination of tools is a really powerful way to create and share your work. This website is a demo that is meant to be used to create your own Quarto website for the final project in MUSA 550.\nQuarto is a relatively new tool, but is becoming popular quickly. It’s a successor to the Rmarkdown ecosystem that combines functionality into a single tool and also extends its computation power to other languages. Most importantly for us, Quarto supports executing Python code, allowing us to convert Jupyter notebooks to HTML and share them online.\n\n\n\n\n\n\nImportant\n\n\n\nThis template site, including the layout it uses, is just a suggested place to start! For your final project, you’re welcome (and encouraged) to make as many changes as you like to best fit your project."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "MUSA 550 Final Project Template",
    "section": "",
    "text": "We can create beautiful websites that describe complex technical analyses in Python using Quarto and deploy them online using GitHub Pages. This combination of tools is a really powerful way to create and share your work. This website is a demo that is meant to be used to create your own Quarto website for the final project in MUSA 550.\nQuarto is a relatively new tool, but is becoming popular quickly. It’s a successor to the Rmarkdown ecosystem that combines functionality into a single tool and also extends its computation power to other languages. Most importantly for us, Quarto supports executing Python code, allowing us to convert Jupyter notebooks to HTML and share them online.\n\n\n\n\n\n\nImportant\n\n\n\nThis template site, including the layout it uses, is just a suggested place to start! For your final project, you’re welcome (and encouraged) to make as many changes as you like to best fit your project."
  },
  {
    "objectID": "index.html#find-out-more",
    "href": "index.html#find-out-more",
    "title": "MUSA 550 Final Project Template",
    "section": "Find out more",
    "text": "Find out more\nThe code for this repository is hosted on our course’s GitHub page: https://github.com/MUSA-550-Fall-2023/quarto-website-template.\nWe covered the basics of getting started with Quarto and GitHub Pages in week 9. Take a look at the slides for lecture 9A to find out more."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "On this about page, you might want to add more information about yourself, the project, or course. Any helpful context could go here!\nMy name is Nick Hand, the instructor for the course. You can find more information about me on my personal website.\nThis site is an example site showing how to use Quarto for the final project for MUSA 550, during fall 2023.\nAdipisicing proident minim non non dolor quis. Pariatur in ipsum aliquip magna. Qui ad aliqua nulla excepteur dolor nostrud quis nisi. Occaecat proident eiusmod in cupidatat. Elit qui laboris sit aliquip proident dolore. Officia commodo commodo in eiusmod aliqua sint cupidatat consectetur aliqua sint reprehenderit.\nOccaecat incididunt esse et elit adipisicing sit est cupidatat consequat. Incididunt exercitation amet dolor non sit anim veniam veniam sint velit. Labore irure reprehenderit ut esse. Minim quis commodo nisi voluptate."
  },
  {
    "objectID": "Our Model/Exploratory-Analysis.html",
    "href": "Our Model/Exploratory-Analysis.html",
    "title": "Predicting Asthma Prevalence by Census Tracts in Philadeplhia, PA",
    "section": "",
    "text": "# Exploratory Analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\nC:\\Users\\cruse\\mambaforge1\\envs\\musa-550-fall-2023\\lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:39: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def nb_dist(x, y):\nC:\\Users\\cruse\\mambaforge1\\envs\\musa-550-fall-2023\\lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:165: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def get_faces(triangle):\nC:\\Users\\cruse\\mambaforge1\\envs\\musa-550-fall-2023\\lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:199: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def build_faces(faces, triangles_is, num_triangles, num_faces_single):\nC:\\Users\\cruse\\mambaforge1\\envs\\musa-550-fall-2023\\lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:261: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def nb_mask_faces(mask, faces):\n\n\n\n\nCode\nhealth_and_wellness = pd.read_csv(\"health_and_wellness.csv\")\nhealth_and_wellness = health_and_wellness.drop(['rank', 'region_name', 'tract_name', 'variable', 'neighborhood_name', 'average_label'], axis=1)\nhealth_and_wellness = health_and_wellness.rename(columns={'value':'hw_value'})\n\n\n\n\nCode\nozone_concentration = pd.read_csv(\"ozone_concentration.csv\")\nozone_concentration = ozone_concentration.drop(['rank', 'region_name', 'tract_name', 'variable','neighborhood_name', 'average_label'], axis=1)\nozone_concentration = ozone_concentration.rename(columns={'value':'oc_value'})\n\n\n\n\nCode\npmc = pd.read_csv(\"particular_matter_concentration.csv\")\npmc = pmc.drop(['rank', 'region_name', 'tract_name', 'variable','neighborhood_name', 'average_label'], axis=1)\npmc = pmc.rename(columns={'value':'pmc_value'})\n\n\n\n## CDC PLACES Data\n\n\n\nCode\nCDC_data = pd.read_csv(\"CDC_data.csv\")\nCDC_data = CDC_data[(CDC_data['StateAbbr'] == 'PA') &\n                         (CDC_data['StateDesc'] == 'Pennsylvania') &\n                         (CDC_data['CountyName'] == 'Philadelphia')]\nCDC_data = CDC_data[['CASTHMA_CrudePrev', 'TractFIPS', 'CSMOKING_CrudePrev']]\nCDC_data = CDC_data.rename(columns={'TractFIPS':'geoid'})\nCDC_data = CDC_data.rename(columns={'CASTHMA_CrudePrev':'asthma_prevalance'})\nCDC_data = CDC_data.rename(columns={'CSMOKING_CrudePrev': 'smoking_prevalance'})\n\n\n\n# Environmental Justice Index Data\n\n\n\nCode\neji_pa = pd.read_csv(\"eji_pa.csv\")\neji_pa = eji_pa[(eji_pa['COUNTY'] == 'Philadelphia')]\neji_pa = eji_pa[['GEOID', 'E_PARK', 'E_HOUAGE','E_ROAD']]\neji_pa = eji_pa.rename(columns={'GEOID': 'geoid'})\n\n\n\n\nCode\ncensustracts = gpd.read_file('Census_Tracts_2010.geojson')\ntract_and_geoid = censustracts[['GEOID10', 'TRACTCE10']]\ntract_and_geoid = tract_and_geoid.rename(columns = {'TRACTCE10':'tract'})\ncensustracts = censustracts[['GEOID10', 'geometry']]\ncensustracts = censustracts.rename(columns = {'GEOID10':'geoid'})\ncensustracts['geoid'] = censustracts['geoid'].astype(np.int64)\n\n\n\n# Philly Demographics\n\n\n\nCode\nvariables = [\n    \"NAME\",\n    \"B03002_001E\",\n    \"B03002_003E\", \n    \"B03002_004E\", \n    \"B03002_005E\", \n    \"B03002_006E\", \n    \"B03002_007E\", \n    \"B03002_008E\", \n    \"B03002_009E\", \n    \"B03002_012E\", \n]\n\n\n\n\nCode\navailable = cenpy.explorer.available()\nacs = cenpy.remote.APIConnection(\"ACSDT5Y2021\")\nphilly_county_code = \"101\"\npa_state_code = \"42\"\n\n\n\n\nCode\nphilly_demographics = acs.query(\n    cols=variables,\n    geo_unit=\"block group:*\",\n    geo_filter={\"state\": pa_state_code, \"county\": philly_county_code, \"tract\": \"*\"},\n)\n\nphilly_demographics = philly_demographics.rename(\n    columns={\n        \"B03002_001E\": \"Total\", \n        \"B03002_003E\": \"White\",  \n        \"B03002_004E\": \"Black\",  \n        \"B03002_005E\": \"AI/AN\", \n        \"B03002_006E\": \"Asian\",  \n        \"B03002_007E\": \"NH/PI\", \n        \"B03002_008E\": \"Other_\",  \n        \"B03002_009E\": \"Two Plus\",\n        \"B03002_012E\": \"Hispanic\",\n    }\n)\nphilly_demographics = pd.merge(philly_demographics, tract_and_geoid, on='tract', how='inner')\nphilly_demographics = philly_demographics.rename(columns = {'GEOID10':'geoid'})\n\n\n\n\nCode\nphilly_demographics['Black'] = pd.to_numeric(philly_demographics['Black'])\nphilly_demographics['Total'] = pd.to_numeric(philly_demographics['Total'])\nphilly_demographics['blk_percent'] = (philly_demographics['Black'] / philly_demographics['Total']) * 100\n\n\n\n\nCode\nphilly_demographics['White'] = pd.to_numeric(philly_demographics['White'])\nphilly_demographics['white_percent'] = (philly_demographics['White'] / philly_demographics['Total']) * 100\nphilly_demographics['Hispanic'] = pd.to_numeric(philly_demographics['Hispanic'])\nphilly_demographics['latino_percent'] = (philly_demographics['Hispanic'] / philly_demographics['Total']) * 100\nphilly_demographics['Asian'] = pd.to_numeric(philly_demographics['Asian'])\nphilly_demographics['asian_percent'] = (philly_demographics['Asian'] / philly_demographics['Total']) * 100\nphilly_demographics['AI/AN'] = pd.to_numeric(philly_demographics['AI/AN'])\nphilly_demographics['NH/PI'] = pd.to_numeric(philly_demographics['NH/PI'])\nphilly_demographics['Other_'] = pd.to_numeric(philly_demographics['Other_'])\nphilly_demographics['Two Plus'] = pd.to_numeric(philly_demographics['Two Plus'])\ncolumns_to_sum = [\"AI/AN\", \"NH/PI\", \"Other_\", \"Two Plus\"]\nphilly_demographics['other_percent'] = (philly_demographics[columns_to_sum].sum(axis=1) / philly_demographics['Total']) * 100\nphilly_demographics = philly_demographics[['blk_percent','white_percent','latino_percent', 'asian_percent', 'other_percent', 'geoid']] \n\n\n\n\nCode\nphilly_demographics['geoid'] = philly_demographics['geoid'].astype('int64')\nphilly_demographics = philly_demographics.dropna()\n\n\n\n## Final Dataset\n\n\n\nCode\nregression_df = pd.merge(health_and_wellness, ozone_concentration, on='geoid', how='inner')\nregression_df = pd.merge(regression_df, pmc, on='geoid', how='inner')\nregression_df = pd.merge(regression_df, CDC_data, on='geoid', how='inner')\nregression_df = pd.merge(regression_df, eji_pa, on='geoid', how='inner')\nregression_df = pd.merge(regression_df, philly_demographics, on='geoid', how='inner')\n\n\n\n\nCode\nregression_df.to_csv('regression_df.csv', index=False)\nregression_df.head()\n\n\n\n\n\n\n\n\n\ngeoid\nhw_value\noc_value\npmc_value\nasthma_prevalance\nsmoking_prevalance\nE_PARK\nE_HOUAGE\nE_ROAD\nblk_percent\nwhite_percent\nlatino_percent\nasian_percent\nother_percent\n\n\n\n\n0\n42101000200\n74.596253\n43.920837\n9.267069\n8.8\n14.8\n100.0\n68.17\n100.0\n5.131698\n14.577657\n7.402361\n65.667575\n7.220708\n\n\n1\n42101000200\n74.596253\n43.920837\n9.267069\n8.8\n14.8\n100.0\n68.17\n100.0\n4.251386\n55.452865\n0.000000\n39.279113\n1.016636\n\n\n2\n42101000200\n74.596253\n43.920837\n9.267069\n8.8\n14.8\n100.0\n68.17\n100.0\n41.538462\n39.230769\n6.153846\n13.076923\n0.000000\n\n\n3\n42101000300\n74.249221\n43.472629\n8.443596\n9.9\n8.6\n100.0\n63.11\n100.0\n2.544333\n60.061681\n5.551272\n12.181958\n19.660756\n\n\n4\n42101000300\n74.249221\n43.472629\n8.443596\n9.9\n8.6\n100.0\n63.11\n100.0\n3.191489\n63.829787\n0.000000\n12.234043\n20.744681\n\n\n\n\n\n\n\n\n\nCode\ndef plot_regression(x_variable, y_variable):\n    plt.figure(figsize=(8, 6))\n    \n    # Plot regression plot\n    sns.regplot(x=regression_df[x_variable], y=regression_df[y_variable])\n    \n    plt.title(f'Regression Plot - Asthma Prevalance vs. {x_variable}')\n    plt.xlabel('Predictor')\n    plt.ylabel('Asthma Prevalance')\n    plt.show()\n\n# List of variables in the dataset excluding 'asthma_prevalance' and 'geoid'\nvariables = [col for col in regression_df.columns if col not in [\"asthma_prevalance\", \"geoid\"]]\ny_variabless = [col for col in regression_df.columns if col in [\"asthma_prevalance\"]]\n\n# Create interactive widgets for x-axis and y-axis variables\nx_variable_dropdown = widgets.Dropdown(options=variables, description='X-axis Variable')\ny_variable_dropdown = widgets.Dropdown(options=y_variabless, description='Y-axis Variable')\n\n# Use the interact function to link the widgets to the plot function\ninteract(plot_regression, x_variable=x_variable_dropdown, y_variable=y_variable_dropdown);\n\n\n\n\n\n\nregression_gdf = pd.merge(regression_df, censustracts, on='geoid', how='inner')\nregression_gdf = gpd.GeoDataFrame(regression_gdf, geometry='geometry')\n\n\ndef generate_choropleth(variable):\n    choropleth_map = regression_gdf.hvplot(geo=True, c=variable, cmap='viridis', colorbar=True, width=800, height=600)\n    return choropleth_map\n\nvariables = [col for col in regression_gdf.columns if col not in [\"geoid\", \"geometry\"]]\n\n# Create a widget for variable selection\nvariable_dropdown = pn.widgets.Select(options=variables, value=variables[0], name='Select Variable')\n\n# Use interact from panel to generate the choropleth map based on the selected variable\n@pn.depends(variable_dropdown.param.value)\ndef update_choropleth(variable):\n    return generate_choropleth(variable)\n\n# Combine the variable dropdown and the choropleth map\ndashboard = pn.Column(\n    pn.Row(variable_dropdown),\n    pn.Row(update_choropleth)\n)\n\ndashboard"
  },
  {
    "objectID": "Our Model/Predictions.html",
    "href": "Our Model/Predictions.html",
    "title": "Predicting Asthma Prevalence by Census Tracts in Philadeplhia, PA",
    "section": "",
    "text": "# Predictions"
  }
]